{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "999e8398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T20:11:45.933541Z",
     "iopub.status.busy": "2024-10-14T20:11:45.932274Z",
     "iopub.status.idle": "2024-10-14T20:11:47.990824Z",
     "shell.execute_reply": "2024-10-14T20:11:47.989606Z"
    },
    "papermill": {
     "duration": 2.069642,
     "end_time": "2024-10-14T20:11:47.993709",
     "exception": false,
     "start_time": "2024-10-14T20:11:45.924067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90183123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T20:11:48.007822Z",
     "iopub.status.busy": "2024-10-14T20:11:48.006638Z",
     "iopub.status.idle": "2024-10-14T20:11:48.012739Z",
     "shell.execute_reply": "2024-10-14T20:11:48.011586Z"
    },
    "papermill": {
     "duration": 0.015356,
     "end_time": "2024-10-14T20:11:48.015125",
     "exception": false,
     "start_time": "2024-10-14T20:11:47.999769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "aad1 = ['B004NWLM8K', 'B004Q1NH4U', 'B004LPBTAA']\n",
    "aad2 = ['B004S6NAOU', 'B004R6HTWU', 'B004N8KDNY']\n",
    "aad3 = ['B004KA0RBS', 'B004NPELDA', 'B004L26XXQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "196d5eee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T20:11:48.028218Z",
     "iopub.status.busy": "2024-10-14T20:11:48.027788Z",
     "iopub.status.idle": "2024-10-14T20:11:48.045727Z",
     "shell.execute_reply": "2024-10-14T20:11:48.044474Z"
    },
    "papermill": {
     "duration": 0.027325,
     "end_time": "2024-10-14T20:11:48.048205",
     "exception": false,
     "start_time": "2024-10-14T20:11:48.020880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### this cell is only for declaring functions\n",
    "\n",
    "def readData(filePath): # reads the file and returns a list of the ratings given to a review\n",
    "    ratings = []\n",
    "    identifiers = []\n",
    "    texts = []\n",
    "    file = open(filePath)\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        ratings.append(int(line.split('\\t')[0]))\n",
    "        identifiers.append(line.split('\\t')[1])\n",
    "        texts.append(line.split('\\t')[2])\n",
    "    return ratings, identifiers, texts\n",
    "\n",
    "\n",
    "def giveMeBag(trainData): # creates a count vectorizer and retrns its features bag of words and a list of its words to be used as vocabulary for another count vectorizer\n",
    "    trainingCVect = CountVectorizer(max_features=30000,stop_words='english')\n",
    "    training_bow = trainingCVect.fit_transform(trainData)\n",
    "    training_words = trainingCVect.get_feature_names_out()\n",
    "    return training_bow,training_words\n",
    "\n",
    "def giveMeTreeTrained(training_data,training_labels): # creates and trains a decision tree\n",
    "    dec_tree = DecisionTreeClassifier()\n",
    "    dec_tree.fit(training_data,training_labels)\n",
    "    return dec_tree\n",
    "\n",
    "def giveMeKnn(training_data,training_labels,k): # creates and trains a knn classifier \n",
    "    knnc = KNeighborsClassifier(n_neighbors=k)\n",
    "    knnc.fit(training_data,training_labels)\n",
    "    return knnc\n",
    "\n",
    "def giveMeForest(training_data,training_labels,n): #creates a random forest classifier, trains it and returns the trained forest\n",
    "    forest = RandomForestClassifier(n_estimators=n)\n",
    "    forest.fit(training_data,training_labels)\n",
    "    return forest\n",
    "\n",
    "def giveMeLSVM(training_data,training_label): #creates a linear SVM classifier, trains it and returns the trained classifier\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(training_data,training_label)\n",
    "    return svm\n",
    "\n",
    "def giveMeNLSVM(training_data,training_label): #creates a non linear SVM classifier, trains it and returns the trained classifier\n",
    "    svm = SVC(kernel='rbf')\n",
    "    svm.fit(training_data,training_label)\n",
    "    return svm\n",
    "\n",
    "def giveMeGoodApps(predictedLab,appList): #taking as input the predicted labels of the test data ans the identifiers of the test data, it returns a new list containing only apps with predicted positive sentiment (3)\n",
    "    goodApps = []\n",
    "    counter = 0\n",
    "    for label in predictedLab:\n",
    "        if label == 3:\n",
    "            goodApps.append(appList[counter])\n",
    "        counter += 1\n",
    "    return goodApps\n",
    "\n",
    "def giveMeBadApps(predictedLab,appList): #opposite of giveMeGoodApps\n",
    "    badApps = []\n",
    "    counter = 0\n",
    "    for label in predictedLab:\n",
    "        if label == 1:\n",
    "            badApps.append(appList[counter])\n",
    "        counter += 1\n",
    "    return badApps\n",
    "\n",
    "def giveMeBestDev(appList): # taking in as input all the apps with predicted positive sentiment, this function counts each instance where the identifier of the app is one of our observed 9 and adds 1 to the proper developer company.\n",
    "    aad1Num, aad2Num, aad3Num = 0,0,0\n",
    "    for app in appList:\n",
    "        if app in aad1:\n",
    "            aad1Num += 1\n",
    "        elif app in aad2:\n",
    "            aad2Num += 1\n",
    "        elif app in aad3:\n",
    "            aad3Num += 1\n",
    "    return aad1Num, aad2Num, aad3Num\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41caf026",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T20:11:48.061171Z",
     "iopub.status.busy": "2024-10-14T20:11:48.060706Z",
     "iopub.status.idle": "2024-10-14T20:11:50.413448Z",
     "shell.execute_reply": "2024-10-14T20:11:50.412416Z"
    },
    "papermill": {
     "duration": 2.362404,
     "end_time": "2024-10-14T20:11:50.416261",
     "exception": false,
     "start_time": "2024-10-14T20:11:48.053857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instanciations\n",
    "trainingRatings,trainingIdentifiers,trainingReviews = readData('/kaggle/input/slightlylessbasicsentimentanalysis/reviews_Apps_for_Android_5.training.txt') # training instances\n",
    "trainingWordsBag,trainingWords = giveMeBag(trainingReviews) # method which creates a training bag of words and vocabulary to use for test\n",
    "\n",
    "testRatings,testIdentifiers,testReviews = readData('/kaggle/input/slightlylessbasicsentimentanalysis/reviews_Apps_for_Android_5.test.txt') # reading test data\n",
    "\n",
    "testCV = CountVectorizer(stop_words='english', vocabulary=trainingWords) # create test count vectoriser using the training vocabulary\n",
    "testWordsBag = testCV.fit_transform(testReviews) # create bag of test words to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca3c798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T20:11:50.429677Z",
     "iopub.status.busy": "2024-10-14T20:11:50.429254Z",
     "iopub.status.idle": "2024-10-14T20:11:59.027357Z",
     "shell.execute_reply": "2024-10-14T20:11:59.026171Z"
    },
    "papermill": {
     "duration": 8.608605,
     "end_time": "2024-10-14T20:11:59.030617",
     "exception": false,
     "start_time": "2024-10-14T20:11:50.422012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREE RESULTS\n",
      "-------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.45      0.41      0.43      3469\n",
      "           2       0.21      0.19      0.20      2087\n",
      "           3       0.81      0.85      0.83     14443\n",
      "\n",
      "    accuracy                           0.70     19999\n",
      "   macro avg       0.49      0.48      0.49     19999\n",
      "weighted avg       0.69      0.70      0.69     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DECISION TREE TRAINING\n",
    "trainedTree = giveMeTreeTrained(trainingWordsBag,trainingRatings) # trained tree from training data\n",
    "DTtestPredLabels = trainedTree.predict(testWordsBag) # use the earlier trained decision tree to predict the labels of the test\n",
    "\n",
    "#compute precision, recall and f-measure for each classification label (DECISION TREE)\n",
    "print('DECISION TREE RESULTS\\n-------------------------------------------------------------------------------')\n",
    "print(classification_report(testRatings,DTtestPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c921bf8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T20:11:59.048286Z",
     "iopub.status.busy": "2024-10-14T20:11:59.047838Z",
     "iopub.status.idle": "2024-10-14T20:12:14.877476Z",
     "shell.execute_reply": "2024-10-14T20:12:14.876210Z"
    },
    "papermill": {
     "duration": 15.84134,
     "end_time": "2024-10-14T20:12:14.880122",
     "exception": false,
     "start_time": "2024-10-14T20:11:59.038782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN (K=1) RESULTS\n",
      "-------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.34      0.32      3469\n",
      "           2       0.13      0.13      0.13      2087\n",
      "           3       0.78      0.75      0.76     14443\n",
      "\n",
      "    accuracy                           0.61     19999\n",
      "   macro avg       0.40      0.41      0.40     19999\n",
      "weighted avg       0.63      0.61      0.62     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN (K=1) TRAINING\n",
    "trainedK = giveMeKnn(trainingWordsBag,trainingRatings,1) # trained tree from training data\n",
    "K1testPredLabels = trainedK.predict(testWordsBag) # use the earlier trained decision tree to predict the labels of the test\n",
    "#compute precision, recall and f-measure for each classification label (DECISION TREE)\n",
    "print('K-NN (K=1) RESULTS\\n-------------------------------------------------------------------------------')\n",
    "print(classification_report(testRatings,K1testPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ace777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T20:12:14.894414Z",
     "iopub.status.busy": "2024-10-14T20:12:14.893344Z",
     "iopub.status.idle": "2024-10-14T20:12:32.799200Z",
     "shell.execute_reply": "2024-10-14T20:12:32.797995Z"
    },
    "papermill": {
     "duration": 17.915881,
     "end_time": "2024-10-14T20:12:32.801915",
     "exception": false,
     "start_time": "2024-10-14T20:12:14.886034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN (K=3) RESULTS\n",
      "-------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.31      0.43      0.36      3469\n",
      "           2       0.19      0.06      0.09      2087\n",
      "           3       0.79      0.79      0.79     14443\n",
      "\n",
      "    accuracy                           0.65     19999\n",
      "   macro avg       0.43      0.43      0.41     19999\n",
      "weighted avg       0.64      0.65      0.64     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN (K=3) TRAINING\n",
    "trainedK3 = giveMeKnn(trainingWordsBag,trainingRatings,3) # trained tree from training data\n",
    "K3testPredLabels = trainedK3.predict(testWordsBag) # use the earlier trained decision tree to predict the labels of the test\n",
    "\n",
    "#compute precision, recall and f-measure for each classification label (DECISION TREE)\n",
    "print('K-NN (K=3) RESULTS\\n-------------------------------------------------------------------------------')\n",
    "print(classification_report(testRatings,K3testPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96274133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T20:12:32.815985Z",
     "iopub.status.busy": "2024-10-14T20:12:32.815505Z",
     "iopub.status.idle": "2024-10-14T20:12:52.263863Z",
     "shell.execute_reply": "2024-10-14T20:12:52.262780Z"
    },
    "papermill": {
     "duration": 19.458339,
     "end_time": "2024-10-14T20:12:52.266401",
     "exception": false,
     "start_time": "2024-10-14T20:12:32.808062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN (K=15) RESULTS\n",
      "-------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.16      0.23      3469\n",
      "           2       0.24      0.03      0.05      2087\n",
      "           3       0.75      0.96      0.84     14443\n",
      "\n",
      "    accuracy                           0.72     19999\n",
      "   macro avg       0.47      0.38      0.37     19999\n",
      "weighted avg       0.64      0.72      0.65     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN (K=15) TRAINING\n",
    "trainedK15 = giveMeKnn(trainingWordsBag,trainingRatings,15) # trained tree from training data\n",
    "K15testPredLabels = trainedK15.predict(testWordsBag) # use the earlier trained decision tree to predict the labels of the test\n",
    "\n",
    "#compute precision, recall and f-measure for each classification label (DECISION TREE)\n",
    "print('K-NN (K=15) RESULTS\\n-------------------------------------------------------------------------------')\n",
    "print(classification_report(testRatings,K15testPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8c35c2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T20:12:52.280092Z",
     "iopub.status.busy": "2024-10-14T20:12:52.279641Z",
     "iopub.status.idle": "2024-10-14T20:13:11.730016Z",
     "shell.execute_reply": "2024-10-14T20:13:11.728665Z"
    },
    "papermill": {
     "duration": 19.460381,
     "end_time": "2024-10-14T20:13:11.732830",
     "exception": false,
     "start_time": "2024-10-14T20:12:52.272449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN (K=20) RESULTS\n",
      "-------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.10      0.16      3469\n",
      "           2       0.23      0.02      0.03      2087\n",
      "           3       0.74      0.98      0.84     14443\n",
      "\n",
      "    accuracy                           0.72     19999\n",
      "   macro avg       0.48      0.36      0.34     19999\n",
      "weighted avg       0.64      0.72      0.64     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN (K=20) TRAINING\n",
    "trainedK20 = giveMeKnn(trainingWordsBag,trainingRatings,20) # trained tree from training data\n",
    "K20testPredLabels = trainedK20.predict(testWordsBag) # use the earlier trained decision tree to predict the labels of the test\n",
    "\n",
    "#compute precision, recall and f-measure for each classification label (DECISION TREE)\n",
    "print('K-NN (K=20) RESULTS\\n-------------------------------------------------------------------------------')\n",
    "print(classification_report(testRatings,K20testPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35178350",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T20:13:11.748371Z",
     "iopub.status.busy": "2024-10-14T20:13:11.747910Z",
     "iopub.status.idle": "2024-10-14T20:13:15.990125Z",
     "shell.execute_reply": "2024-10-14T20:13:15.988727Z"
    },
    "papermill": {
     "duration": 4.253201,
     "end_time": "2024-10-14T20:13:15.993391",
     "exception": false,
     "start_time": "2024-10-14T20:13:11.740190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM RESULTS\n",
      "-------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.54      0.56      3469\n",
      "           2       0.24      0.20      0.22      2087\n",
      "           3       0.85      0.88      0.86     14443\n",
      "\n",
      "    accuracy                           0.75     19999\n",
      "   macro avg       0.56      0.54      0.55     19999\n",
      "weighted avg       0.74      0.75      0.74     19999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Linear SVM\n",
    "lsvm = giveMeLSVM(trainingWordsBag, trainingRatings)\n",
    "LSVMtestPredLabels = lsvm.predict(testWordsBag) # use the earlier trained decision tree to predict the labels of the test\n",
    "\n",
    "#compute precision, recall and f-measure for each classification label\n",
    "print('SVM RESULTS\\n-------------------------------------------------------------------------------')\n",
    "print(classification_report(testRatings,LSVMtestPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8624e968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T20:13:16.007996Z",
     "iopub.status.busy": "2024-10-14T20:13:16.007559Z",
     "iopub.status.idle": "2024-10-14T20:16:46.241255Z",
     "shell.execute_reply": "2024-10-14T20:16:46.240046Z"
    },
    "papermill": {
     "duration": 210.25017,
     "end_time": "2024-10-14T20:16:46.249989",
     "exception": false,
     "start_time": "2024-10-14T20:13:15.999819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Linear SVM RESULTS\n",
      "-------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.42      0.53      3469\n",
      "           2       0.57      0.09      0.16      2087\n",
      "           3       0.80      0.98      0.88     14443\n",
      "\n",
      "    accuracy                           0.79     19999\n",
      "   macro avg       0.70      0.50      0.52     19999\n",
      "weighted avg       0.76      0.79      0.74     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Non Linear SVM\n",
    "svm2 = giveMeNLSVM(trainingWordsBag, trainingRatings)\n",
    "NLSVMtestPredLabels = svm2.predict(testWordsBag) # use the earlier trained decision tree to predict the labels of the test\n",
    "\n",
    "#compute precision, recall and f-measure for each classification label\n",
    "print('Non-Linear SVM RESULTS\\n-------------------------------------------------------------------------------')\n",
    "print(classification_report(testRatings,NLSVMtestPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3c6fb39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T20:16:46.265250Z",
     "iopub.status.busy": "2024-10-14T20:16:46.264791Z",
     "iopub.status.idle": "2024-10-14T20:17:37.715812Z",
     "shell.execute_reply": "2024-10-14T20:17:37.714600Z"
    },
    "papermill": {
     "duration": 51.468637,
     "end_time": "2024-10-14T20:17:37.725162",
     "exception": false,
     "start_time": "2024-10-14T20:16:46.256525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting RESULTS\n",
      "-------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.36      0.46      3469\n",
      "           2       0.32      0.07      0.12      2087\n",
      "           3       0.79      0.95      0.86     14443\n",
      "\n",
      "    accuracy                           0.76     19999\n",
      "   macro avg       0.57      0.46      0.48     19999\n",
      "weighted avg       0.71      0.76      0.71     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Voting based on previous results\n",
    " # Create the voting classifier\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "    ('tree', trainedTree),\n",
    "    ('knn15', trainedK15),\n",
    "    ('knn20', trainedK20),\n",
    "    ('lsvm', lsvm)], voting='hard')\n",
    "\n",
    "# Train the voting classifier on the training data\n",
    "voting_classifier.fit(trainingWordsBag, trainingRatings)\n",
    "\n",
    "# Make predictions on the test data\n",
    "VtestPredLabels = voting_classifier.predict(testWordsBag)\n",
    "\n",
    "#compute precision, recall and f-measure for each classification label (All previous predictions)\n",
    "print('Voting RESULTS\\n-------------------------------------------------------------------------------')\n",
    "print(classification_report(testRatings,VtestPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ae07291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T20:17:37.740820Z",
     "iopub.status.busy": "2024-10-14T20:17:37.740349Z",
     "iopub.status.idle": "2024-10-14T20:17:46.085290Z",
     "shell.execute_reply": "2024-10-14T20:17:46.083897Z"
    },
    "papermill": {
     "duration": 8.355898,
     "end_time": "2024-10-14T20:17:46.087944",
     "exception": false,
     "start_time": "2024-10-14T20:17:37.732046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST RESULTS\n",
      "-------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.36      0.47      3469\n",
      "           2       0.43      0.07      0.11      2087\n",
      "           3       0.78      0.97      0.87     14443\n",
      "\n",
      "    accuracy                           0.77     19999\n",
      "   macro avg       0.63      0.46      0.48     19999\n",
      "weighted avg       0.73      0.77      0.72     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest classifier\n",
    "trainedForest = giveMeForest(trainingWordsBag,trainingRatings,20) # trained forest from training data\n",
    "RFtestPredLabels = trainedForest.predict(testWordsBag) # use the earlier trained decision tree to predict the labels of the test\n",
    "\n",
    "#compute precision, recall and f-measure for each classification label (DECISION TREE)\n",
    "print('RANDOM FOREST RESULTS\\n-------------------------------------------------------------------------------')\n",
    "print(classification_report(testRatings,RFtestPredLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a95865c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T20:17:46.103655Z",
     "iopub.status.busy": "2024-10-14T20:17:46.103189Z",
     "iopub.status.idle": "2024-10-14T20:17:46.234958Z",
     "shell.execute_reply": "2024-10-14T20:17:46.233818Z"
    },
    "papermill": {
     "duration": 0.142832,
     "end_time": "2024-10-14T20:17:46.237653",
     "exception": false,
     "start_time": "2024-10-14T20:17:46.094821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREE\n",
      "AAD 1: 90 \n",
      "AAD 2: 182 \n",
      "AAD 3: 91 \n",
      "_______________________________\n",
      "\n",
      "K-NN (K=15)\n",
      "AAD 1: 104 \n",
      "AAD 2: 260 \n",
      "AAD 3: 143 \n",
      "_______________________________\n",
      "\n",
      "K-NN (K=20)\n",
      "AAD 1: 106 \n",
      "AAD 2: 267 \n",
      "AAD 3: 150 \n",
      "_______________________________\n",
      "\n",
      "Linear SVM\n",
      "AAD 1: 97 \n",
      "AAD 2: 155 \n",
      "AAD 3: 75 \n",
      "_______________________________\n",
      "\n",
      "Non-Linear SVM\n",
      "AAD 1: 106 \n",
      "AAD 2: 223 \n",
      "AAD 3: 115 \n",
      "_______________________________\n",
      "\n",
      "Voting Ensemble\n",
      "AAD 1: 103 \n",
      "AAD 2: 226 \n",
      "AAD 3: 119 \n",
      "_______________________________\n",
      "\n",
      "Random Forest\n",
      "AAD 1: 106 \n",
      "AAD 2: 233 \n",
      "AAD 3: 119 \n",
      "_______________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Aggregating the results to find out which apps have best performance and which company has those apps\n",
    "\n",
    "def printDevResults(predictedLabels): # FUNCTION TO AUTOMATICALLY PRINT result of developers\n",
    "    goodApps = giveMeGoodApps(predictedLabels,testIdentifiers) #returns all apps which were predicted to have positive sentiment\n",
    "    a1,a2,a3= giveMeBestDev(goodApps) #returns the number of positive reviews each developer has\n",
    "    print('AAD 1:', a1, '\\nAAD 2:', a2, '\\nAAD 3:', a3, '\\n_______________________________\\n')\n",
    "\n",
    "# def printDevResults(predictedLabels): # FUNCTION TO AUTOMATICALLY PRINT result of developers\n",
    "#     goodApps = giveMeBadApps(predictedLabels,testIdentifiers) #returns all apps which were predicted to have positive sentiment\n",
    "#     a1,a2,a3= giveMeBestDev(goodApps) #returns the number of positive reviews each developer has\n",
    "#     print('AAD 1:', a1, '\\nAAD 2:', a2, '\\nAAD 3:', a3, '\\n_______________________________\\n')\n",
    "\n",
    "print('DECISION TREE')\n",
    "printDevResults(DTtestPredLabels)\n",
    "\n",
    "print('K-NN (K=15)')\n",
    "printDevResults(K15testPredLabels)\n",
    "\n",
    "print('K-NN (K=20)')\n",
    "printDevResults(K20testPredLabels)\n",
    "\n",
    "print('Linear SVM')\n",
    "printDevResults(LSVMtestPredLabels)\n",
    "\n",
    "print('Non-Linear SVM')\n",
    "printDevResults(NLSVMtestPredLabels)\n",
    "\n",
    "print('Voting Ensemble')\n",
    "printDevResults(VtestPredLabels)\n",
    "\n",
    "print('Random Forest')\n",
    "printDevResults(RFtestPredLabels)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5875749,
     "sourceId": 9625828,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 364.130095,
   "end_time": "2024-10-14T20:17:46.765598",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-14T20:11:42.635503",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
